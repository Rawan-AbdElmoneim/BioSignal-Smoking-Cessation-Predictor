{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23b85d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\users\\rawan\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rawan\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from scikit-optimize) (23.9.7)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-optimize scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3e9e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a065d30",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a68451dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae98a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Rawan\\Desktop\\term 7\\machine learning\\Assignment 3_attachments\\Assignment 3_attachments\\train_Data.csv', index_col= 0)\n",
    "test = pd.read_csv(r'C:\\Users\\Rawan\\Desktop\\term 7\\machine learning\\Assignment 3_attachments\\Assignment 3_attachments\\test_Data.csv', index_col= 0)\n",
    "val = pd.read_csv(r'C:\\Users\\Rawan\\Desktop\\term 7\\machine learning\\Assignment 3_attachments\\Assignment 3_attachments\\val_Data.csv', index_col= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d67515d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AST</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>HDL</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17406</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>-1.076028</td>\n",
       "      <td>0.990459</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>-0.031118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61303</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1.543598</td>\n",
       "      <td>-1.062704</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>-0.599977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71781</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.452087</td>\n",
       "      <td>0.285174</td>\n",
       "      <td>-0.320325</td>\n",
       "      <td>-0.599977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67014</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.379319</td>\n",
       "      <td>-1.062704</td>\n",
       "      <td>-0.320325</td>\n",
       "      <td>-1.168836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73322</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.351190</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>-0.712191</td>\n",
       "      <td>-0.263381</td>\n",
       "      <td>-0.962466</td>\n",
       "      <td>-1.168836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AST  Cholesterol  eyesight(right)       HDL  triglyceride  \\\n",
       "17406  24.0     0.357143         0.368421 -1.076028      0.990459   \n",
       "61303  34.0     0.553571         0.578947  1.543598     -1.062704   \n",
       "71781  17.0     0.440476         0.315789  0.452087      0.285174   \n",
       "67014  38.0     0.327381         0.473684  0.379319     -1.062704   \n",
       "73322  25.0     0.351190         0.473684 -0.712191     -0.263381   \n",
       "\n",
       "       eyesight(left)  height(cm)  Urine protein  smoking  \n",
       "17406        0.000746   -0.031118            0.0        1  \n",
       "61303        0.000746   -0.599977            0.0        1  \n",
       "71781       -0.320325   -0.599977            0.0        1  \n",
       "67014       -0.320325   -1.168836            0.0        0  \n",
       "73322       -0.962466   -1.168836            0.0        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7654c21",
   "metadata": {},
   "source": [
    "## splitting dataset into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f0c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train['smoking']\n",
    "x_train=train.drop(columns=['smoking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03bbe7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test['smoking']\n",
    "x_test=test.drop(columns=['smoking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbc86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val=val['smoking']\n",
    "x_val=val.drop(columns=['smoking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e07fac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>LDL</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>HDL</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>Total Cholesterol</th>\n",
       "      <th>Cholesterol Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17406</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.361842</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>-1.076028</td>\n",
       "      <td>0.990459</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>-0.031118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.124537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61303</th>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1.543598</td>\n",
       "      <td>-1.062704</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>-0.599977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>-0.631807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71781</th>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.452087</td>\n",
       "      <td>0.285174</td>\n",
       "      <td>-0.320325</td>\n",
       "      <td>-0.599977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.606227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67014</th>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.379319</td>\n",
       "      <td>-1.062704</td>\n",
       "      <td>-0.320325</td>\n",
       "      <td>-1.168836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.309524</td>\n",
       "      <td>-0.581288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73322</th>\n",
       "      <td>0.351190</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>-0.712191</td>\n",
       "      <td>-0.263381</td>\n",
       "      <td>-0.962466</td>\n",
       "      <td>-1.168836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.452381</td>\n",
       "      <td>0.117167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cholesterol       LDL  eyesight(right)       HDL  triglyceride  \\\n",
       "17406     0.357143  0.361842         0.368421 -1.076028      0.990459   \n",
       "61303     0.553571  0.513158         0.578947  1.543598     -1.062704   \n",
       "71781     0.440476  0.375000         0.315789  0.452087      0.285174   \n",
       "67014     0.327381  0.375000         0.473684  0.379319     -1.062704   \n",
       "73322     0.351190  0.434211         0.473684 -0.712191     -0.263381   \n",
       "\n",
       "       eyesight(left)  height(cm)  Urine protein  Total Cholesterol  \\\n",
       "17406        0.000746   -0.031118            0.0          -0.833333   \n",
       "61303        0.000746   -0.599977            0.0           0.571429   \n",
       "71781       -0.320325   -0.599977            0.0          -0.285714   \n",
       "67014       -0.320325   -1.168836            0.0          -0.309524   \n",
       "73322       -0.962466   -1.168836            0.0          -0.452381   \n",
       "\n",
       "       Cholesterol Ratio  \n",
       "17406           0.124537  \n",
       "61303          -0.631807  \n",
       "71781          -0.606227  \n",
       "67014          -0.581288  \n",
       "73322           0.117167  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e2954",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38e34c9",
   "metadata": {},
   "source": [
    "## 1)Boosting (AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b128fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7053874168027126\n"
     ]
    }
   ],
   "source": [
    "def compute_error(y, y_pred, w_i):\n",
    "    y = np.array(y)  \n",
    "    y_pred = np.array(y_pred) \n",
    "    return np.sum(w_i * (y != y_pred)) / np.sum(w_i)\n",
    "\n",
    "def compute_alpha(error):\n",
    "    return 0.5 * np.log((1 - error) / error)\n",
    "\n",
    "def update_weights(w_i, alpha, y, y_pred):\n",
    "    return w_i * np.exp(-alpha * y * y_pred)\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, model_params=None, n=100, base_model=None):  \n",
    "        self.alphas = []\n",
    "        self.models = []\n",
    "        self.n = n\n",
    "        self.base_model = base_model\n",
    "        self.model_params = model_params if model_params is not None else {}\n",
    "        self.training_errors = []\n",
    "        self.prediction_errors = []\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'n': self.n, 'model_params': self.model_params,  'base_model': self.base_model}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.alphas = []\n",
    "        self.training_errors = []\n",
    "        w_i = np.ones(len(y)) / len(y)\n",
    "\n",
    "        for m in range(self.n):\n",
    "            if self.base_model is None:\n",
    "                model = DecisionTreeClassifier(max_depth=1)\n",
    "            else:\n",
    "                model = self.base_model.set_params(**self.model_params)\n",
    "\n",
    "\n",
    "            model.fit(x, y, sample_weight=w_i)\n",
    "            y_pred = model.predict(x)\n",
    "\n",
    "            error_m = compute_error(y, y_pred, w_i)\n",
    "            alpha_m = compute_alpha(error_m)\n",
    "\n",
    "            w_i = update_weights(w_i, alpha_m, y, y_pred)\n",
    "\n",
    "            self.models.append(model)\n",
    "            self.alphas.append(alpha_m)\n",
    "            self.training_errors.append(error_m)\n",
    "\n",
    "    def predict(self, x):\n",
    "        weak_preds = np.zeros((len(x), self.n))\n",
    "\n",
    "        for model in range(self.n):\n",
    "            y_pred_model = self.models[model].predict(x) * self.alphas[model]\n",
    "            weak_preds[:, model] = y_pred_model\n",
    "\n",
    "        y_pred = np.sign(weak_preds.sum(axis=1))\n",
    "        return y_pred.astype(int)\n",
    "\n",
    "    def error_rates(self, X, y):\n",
    "        self.prediction_errors = []\n",
    "\n",
    "        for model in range(self.n):\n",
    "            y_pred_model = self.models[model].predict(X)\n",
    "            error_model = compute_error(y, y_pred_model, np.ones(len(y)))\n",
    "            self.prediction_errors.append(error_model)\n",
    "    def score(self, X, y):\n",
    "        # Assuming you want to use accuracy as the scoring metric\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        return accuracy\n",
    "adaboost = AdaBoost()\n",
    "adaboost.fit(x_train, y_train)\n",
    "y_pred = adaboost.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f49513cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'base_model': None, 'model_params': {'max_depth': [1, 2, 3], 'criterion': ['gini', 'entropy']}, 'n': 10}\n",
      "Best Accuracy:  0.7015761263991751\n",
      "Validation Accuracy: 70.38%\n",
      "Test Accuracy: 70.54%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "\n",
    "\n",
    "param_grid = { \n",
    "    'base_model': [None,DecisionTreeClassifier(), LogisticRegression(), KNeighborsClassifier(), LinearRegression()],\n",
    "    'n': [None,10,20,30,80, 100, 120],  # Number of weak learners\n",
    "    'model_params': [\n",
    "        {'max_depth': [1,2,3], 'criterion': ['gini', 'entropy']},  # Parameters for DecisionTreeClassifier\n",
    "        {},  # Parameters for LogisticRegression\n",
    "        {'n_neighbors': list(range(1, 20))},  # Parameters for KNeighborsClassifier\n",
    "        {}\n",
    "    ]\n",
    "}\n",
    "adaboost = AdaBoost()\n",
    "scorer = make_scorer(accuracy_score)\n",
    "grid_search = GridSearchCV(estimator=adaboost, param_grid=param_grid, scoring=scorer, cv=5)#k folds\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "val_accuracy = best_model.score(x_val, y_val)\n",
    "print(\"Validation Accuracy: {:.2f}%\".format(val_accuracy * 100))\n",
    "\n",
    "# Test the best model on the test set\n",
    "test_accuracy = best_model.score(x_test, y_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ab2f20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n': 100, 'model_params': {}, 'base_model': None}\n",
      "Best Accuracy:  0.7015761263991751\n",
      "Validation Accuracy: 70.38%\n",
      "Test Accuracy: 70.54%\n"
     ]
    }
   ],
   "source": [
    "param_dist = { \n",
    "    'base_model': [None,DecisionTreeClassifier(), LogisticRegression(), KNeighborsClassifier(), LinearRegression()],\n",
    "    'n': [None,10,20,30,80, 100, 120],  # Number of weak learners\n",
    "    'model_params': [\n",
    "        {'max_depth': [1,2,3], 'criterion': ['gini', 'entropy']},  # Parameters for DecisionTreeClassifier\n",
    "        {},  # Parameters for LogisticRegression\n",
    "        {'n_neighbors': list(range(1, 20))},  # Parameters for KNeighborsClassifier\n",
    "        {}\n",
    "    ]\n",
    "}\n",
    "adaboost = AdaBoost()\n",
    "scorer = make_scorer(accuracy_score)\n",
    "random_search = RandomizedSearchCV(estimator=adaboost, param_distributions=param_dist, n_iter=18, scoring=scorer, cv=5, random_state=42)\n",
    "random_search.fit(x_train, y_train)\n",
    "print(\"Best Parameters: \", random_search.best_params_)\n",
    "print(\"Best Accuracy: \", random_search.best_score_)\n",
    "\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "val_accuracy = best_model.score(x_val, y_val)\n",
    "print(\"Validation Accuracy: {:.2f}%\".format(val_accuracy * 100))\n",
    "\n",
    "# Test the best model on the test set\n",
    "test_accuracy = best_model.score(x_test, y_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b9044",
   "metadata": {},
   "source": [
    "## 2)Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdc42d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7053874168027126\n"
     ]
    }
   ],
   "source": [
    "class Bagger:\n",
    "    \n",
    "    def __init__(self, seed=None,  model_params=None, M=100, base_model=None):\n",
    "        self.alphas = []\n",
    "        self.models = []\n",
    "        self.M = M\n",
    "        self.base_model = base_model\n",
    "        self.model_params = model_params if model_params is not None else {}\n",
    "        self.seed = seed\n",
    "        self.training_errors = []\n",
    "        self.prediction_errors = []\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {'M': self.M, 'model_params': self.model_params,  'base_model': self.base_model}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    #it samples the training data with replacement \n",
    "    #and fits a base model (DecisionTreeClassifier by default) to this sampled data.\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.N, self.D = x_train.shape# .N -> num of samples , .d -> num of features\n",
    "        self.y_train = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "        np.random.seed(self.seed)\n",
    "        for m in range(self.M):\n",
    "            sample = np.random.choice(np.arange(self.N), size=self.N, replace=True)\n",
    "            sample = sample.astype(int)\n",
    "            if isinstance(x_train, pd.DataFrame):\n",
    "                x_train_m = x_train.iloc[sample]\n",
    "            else:\n",
    "                x_train_m = x_train[sample]\n",
    "            y_train_m = self.y_train[sample]\n",
    "            if self.base_model is None:\n",
    "                model = DecisionTreeClassifier(max_depth=1)\n",
    "            else:\n",
    "                model = self.base_model.set_params(**self.model_params)\n",
    "\n",
    "            model.fit(x_train_m, y_train_m)\n",
    "            self.models.append(model)\n",
    "\n",
    "\n",
    "      \n",
    "    def predict(self, x_test):\n",
    "        y_test_hats = np.empty((len(self.models), len(x_test)))\n",
    "        for i, model in enumerate(self.models):\n",
    "            y_test_hats[i] = model.predict(x_test)\n",
    "        \n",
    "        return y_test_hats.mean(0)\n",
    "\n",
    "    def calculate_accuracy(self, y_true, y_pred):\n",
    "        y_pred_binary = (y_pred > 0.5).astype(int)  # Assuming binary classification\n",
    "        return accuracy_score(y_true, y_pred_binary)\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return accuracy_score(y, predictions)\n",
    "\n",
    "bagger = Bagger(M=30, seed=123)\n",
    "bagger.fit(x_train, y_train)\n",
    "y_test_hat = bagger.predict(x_test)\n",
    "\n",
    "accuracy = bagger.calculate_accuracy(y_test, y_test_hat)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c1b0cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'M': 20, 'base_model': LogisticRegression(), 'model_params': {}}\n",
      "Best Accuracy:  0.7154083374794695\n",
      "Validation Accuracy: 71.28%\n",
      "Test Accuracy: 71.53%\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'base_model': [DecisionTreeClassifier(), LogisticRegression(), KNeighborsClassifier(), LinearRegression()],\n",
    "    'M': [None,10,20,30,80, 100, 120],  # Number of weak learners\n",
    "    'model_params': [\n",
    "        {'max_depth': [1,2,3], 'criterion': ['gini', 'entropy']},  # Parameters for DecisionTreeClassifier\n",
    "        {},  # Parameters for LogisticRegression\n",
    "        {'n_neighbors': list(range(1, 20))},  # Parameters for KNeighborsClassifier\n",
    "    ]\n",
    "}\n",
    "bagger = Bagger(M=30, seed=123)\n",
    "scorer = make_scorer(accuracy_score)\n",
    "grid_search = GridSearchCV(estimator=bagger, param_grid=param_grid, scoring=scorer, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "val_accuracy = best_model.score(x_val, y_val)\n",
    "print(\"Validation Accuracy: {:.2f}%\".format(val_accuracy * 100))\n",
    "\n",
    "# Test the best model on the test set\n",
    "test_accuracy = best_model.score(x_test, y_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6814345d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'model_params': {}, 'base_model': LogisticRegression(), 'M': 10}\n",
      "Best Accuracy:  0.7149329090393655\n",
      "Validation Accuracy: 71.27%\n",
      "Test Accuracy: 71.47%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the parameter distributions for RandomizedSearchCV\n",
    "param_dist =  {\n",
    "    'base_model': [None,DecisionTreeClassifier(), LogisticRegression(), KNeighborsClassifier(), LinearRegression()],\n",
    "    'M': [None,10,20,30,80, 100, 120],  # Number of weak learners\n",
    "    'model_params': [\n",
    "        {'max_depth': [1,2,3], 'criterion': ['gini', 'entropy']},  # Parameters for DecisionTreeClassifier\n",
    "        {},  # Parameters for LogisticRegression\n",
    "        {'n_neighbors': list(range(1, 20))},  # Parameters for KNeighborsClassifier\n",
    "        {}\n",
    "    ]\n",
    "}\n",
    "bagger = Bagger(M=30, seed=123)\n",
    "scorer = make_scorer(accuracy_score)\n",
    "random_search = RandomizedSearchCV(estimator=bagger, param_distributions=param_dist, n_iter=18, scoring=scorer, cv=5, random_state=42)\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Parameters: \", random_search.best_params_)\n",
    "print(\"Best Accuracy: \", random_search.best_score_)\n",
    "\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "val_accuracy = best_model.score(x_val, y_val)\n",
    "print(\"Validation Accuracy: {:.2f}%\".format(val_accuracy * 100))\n",
    "\n",
    "# Test the best model on the test set\n",
    "test_accuracy = best_model.score(x_test, y_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203212d9",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e08e3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7294152120222697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, M=100, max_depth=100, min_size=2, criterion='gini', seed=None):\n",
    "        self.models = []  # List to store individual DecisionTree models\n",
    "        self.M = M\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.seed = seed\n",
    "        self.training_errors = []\n",
    "        self.prediction_errors = []\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'M': self.M, 'criterion': self.criterion, 'max_depth': self.max_depth, 'min_size': self.min_size}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.N, self.D = x_train.shape\n",
    "        self.y_train = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "\n",
    "        seed = self.seed if self.seed is not None else np.random.randint(1, 1000)  # Set a random seed if None\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        for _ in range(self.M):\n",
    "            sample = np.random.choice(np.arange(self.N), size=self.N, replace=True)\n",
    "            sample = sample.astype(int)\n",
    "\n",
    "            if isinstance(x_train, pd.DataFrame):\n",
    "                x_train_m = x_train.iloc[sample]\n",
    "            else:\n",
    "                x_train_m = x_train[sample]\n",
    "\n",
    "            y_train_m = self.y_train[sample]\n",
    "\n",
    "            model = DecisionTreeClassifier(max_depth=self.max_depth, min_samples_split=self.min_size, criterion=self.criterion)\n",
    "            model.fit(x_train_m, y_train_m)\n",
    "            self.models.append(model)\n",
    "\n",
    "        # Return the fitted model\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        y_test_hats = np.empty((len(self.models), len(x_test)))\n",
    "        for i, model in enumerate(self.models):\n",
    "            y_test_hats[i] = model.predict(x_test)\n",
    "\n",
    "        return y_test_hats.mean(0)\n",
    "\n",
    "    def calculate_accuracy(self, y_true, y_pred):\n",
    "        y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "        return accuracy_score(y_true, y_pred_binary)\n",
    "\n",
    "# Example usage:\n",
    "random_forest = RandomForest(M=30, max_depth=20, min_size=5, seed=123)\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_test_hat = random_forest.predict(x_test)\n",
    "\n",
    "accuracy = random_forest.calculate_accuracy(y_test, y_test_hat)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "afc6b913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'M': 50, 'criterion': 'entropy', 'max_depth': 10, 'min_size': 10}\n",
      "Best Accuracy:  0.7407852886479235\n",
      "Test Accuracy: 0.7395453974632676\n",
      "Validation Accuracy: 0.7402461486939049\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'M': [10, 20, 30, 50],\n",
    "    'max_depth': [10, 20, 30, 40],\n",
    "    'min_size': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate your RandomForest class\n",
    "random_forest = RandomForest(seed=123)\n",
    "scorer = make_scorer(random_forest.calculate_accuracy)\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Accuracy: \", best_score)\n",
    "\n",
    "# Test the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_test_hat = best_model.predict(x_test)\n",
    "test_accuracy = best_model.calculate_accuracy(y_test, y_test_hat)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "y_val_hat = best_model.predict(x_val)\n",
    "val_accuracy = best_model.calculate_accuracy(y_val, y_val_hat)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f830eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'min_size': 5, 'max_depth': 10, 'criterion': 'gini', 'M': 50}\n",
      "Best Accuracy:  0.7407494033466662\n",
      "Test Accuracy: 0.7402570220603625\n",
      "Validation Accuracy: 0.7391577361018085\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'M': [10, 20, 30, 50],  \n",
    "    'max_depth': [10, 20, 30, 40],  \n",
    "    'min_size': [2, 5, 10],  \n",
    "    'criterion': ['gini', 'entropy']  \n",
    "}\n",
    "\n",
    "random_forest = RandomForest(seed=123)\n",
    "scorer = make_scorer(random_forest.calculate_accuracy)\n",
    "random_search = RandomizedSearchCV(estimator=random_forest, param_distributions=param_dist, n_iter=10, scoring=scorer, cv=5, random_state=42)\n",
    "\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Accuracy: \", best_score)\n",
    "\n",
    "# Test the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "y_test_hat = best_model.predict(x_test)\n",
    "test_accuracy = best_model.calculate_accuracy(y_test, y_test_hat)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "y_val_hat = best_model.predict(x_val)\n",
    "val_accuracy = best_model.calculate_accuracy(y_val, y_val_hat)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e7554d",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d0dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\rawan\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f501c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7379547071874084\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Instantiate XGBoost Classifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb54caa8",
   "metadata": {},
   "source": [
    "## catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b038155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\rawan\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2022.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\rawan\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d313f234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iterations': 5, 'learning_rate': 0.1, 'loss_function': 'Logloss'}\n",
      "CatBoost Test Accuracy: 0.7351500690694462\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Convert categorical features to string type\n",
    "x_train_cat = x_train.astype(str)\n",
    "x_val_cat = x_val.astype(str)\n",
    "\n",
    "clf = CatBoostClassifier(\n",
    "    iterations=5, \n",
    "    learning_rate=0.1,\n",
    "    loss_function='Logloss'  # You can uncomment this line if you want to explicitly specify the loss function\n",
    ")\n",
    "\n",
    "cat_features = list(range(0, x_train.shape[1]))\n",
    "clf.fit(x_train_cat, y_train, \n",
    "        cat_features=cat_features, \n",
    "        eval_set=(x_val_cat, y_val), \n",
    "        verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "print(clf.get_params())\n",
    "\n",
    "y_pred_test = clf.predict(x_test.astype(str))\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print('CatBoost Test Accuracy:', accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f814917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
